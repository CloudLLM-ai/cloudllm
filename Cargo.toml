[package]
name = "cloudllm"
version = "0.2.12"
authors = ["Angel Leon <gubatron@gmail.com>"]
edition = "2018"
description = "A Rust library for bridging applications with remote LLMs across various platforms."
repository = "https://github.com/CloudLLM-ai/cloudllm"
license = "MIT"
documentation = "https://docs.rs/cloudllm/latest/cloudllm/"

[dependencies]
tokio = { version = "1.47.1", features = ["full"] }

# This is my own fork of the OpenAI Rust client, which has a few improvements over the original.
# https://github.com/gubatron/openai-rust
openai-rust2 = { version = "1.6.0" }

async-trait = "0.1.88"
log = "0.4.27"
env_logger = "0.11.8"
once_cell = "1.21.0"
dashmap = "6.1.0"
reqwest = { version = "0.12.9", features = ["json"] }